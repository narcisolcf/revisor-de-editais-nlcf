"""
LicitaReview - Testes e Exemplos dos Modelos

Este arquivo demonstra como usar os modelos implementados e serve
como teste b√°sico das funcionalidades principais.
"""

import json
from datetime import datetime
from typing import Dict, Any

from models import (
    # Document Models
    Document,
    DocumentType,
    DocumentClassification,
    DocumentStatus,
    DocumentMetadata,
    LicitationModality,
    
    # Analysis Models
    AnalysisRequest,
    AnalysisResult,
    AnalysisFinding,
    ConformityScore,
    ProblemSeverity,
    ProblemCategory,
    
    # Config Models (CORE DIFERENCIAL)
    OrganizationConfig,
    AnalysisWeights,
    CustomRule,
    AnalysisPreset,
    OrganizationTemplate,
    TemplateSection
)

from models.utils import (
    ModelConverter,
    ValidationUtils,
    SerializationUtils,
    serialize_for_api,
    create_document_summary,
    create_dashboard_data,
    prepare_frontend_config
)


def test_document_models():
    """Testa modelos de documento."""
    print("üß™ Testando Document Models...")
    
    # 1. Criar classifica√ß√£o de documento
    classification = DocumentClassification(
        primary_category="licitacao",
        secondary_category="bens_servicos",
        document_type=DocumentType.EDITAL,
        modality=LicitationModality.PREGAO_ELETRONICO,
        complexity_level="media"
    )
    
    print(f"‚úÖ Classifica√ß√£o criada: {classification.to_hierarchy_string()}")
    
    # 2. Criar metadados
    metadata = DocumentMetadata(
        file_name="edital_pregao_123_2025.pdf",
        file_size=2048000,  # 2MB
        file_type="application/pdf",
        page_count=25,
        word_count=15000,
        ocr_confidence=0.95,
        extraction_method="hybrid",
        language="pt-BR",
        organization_id="org_prefeitura_sp"
    )
    
    print(f"‚úÖ Metadados criados: {metadata.file_name} ({metadata.file_size} bytes)")
    
    # 3. Criar documento completo
    document = Document(
        title="Edital de Preg√£o Eletr√¥nico n¬∫ 123/2025 - Aquisi√ß√£o de Material de Escrit√≥rio",
        content="EDITAL DE PREG√ÉO ELETR√îNICO N¬∫ 123/2025\n\nA Prefeitura Municipal...",
        classification=classification,
        metadata=metadata,
        organization_id="org_prefeitura_sp",
        created_by="user_admin_123"
    )
    
    print(f"‚úÖ Documento criado: {document.id}")
    print(f"   T√≠tulo: {document.title[:50]}...")
    print(f"   Status: {document.status.value}")
    print(f"   Preview: {document.get_content_preview(100)}")
    
    # 4. Testar m√©todos do documento
    document.change_status(DocumentStatus.PROCESSING)
    print(f"‚úÖ Status alterado para: {document.status.value}")
    
    # 5. Criar nova vers√£o
    new_version = document.create_new_version(
        "EDITAL DE PREG√ÉO ELETR√îNICO N¬∫ 123/2025 - VERS√ÉO REVISADA...",
        "user_revisor_456"
    )
    print(f"‚úÖ Nova vers√£o criada: {new_version.id} (v{new_version.version})")
    
    return document


def test_config_models():
    """üöÄ Testa modelos de configura√ß√£o (CORE DIFERENCIAL)."""
    print("\nüöÄ Testando Config Models (CORE DIFERENCIAL)...")
    
    # 1. Criar pesos personalizados
    custom_weights = AnalysisWeights(
        structural=20.0,
        legal=50.0,    # Foco em conformidade jur√≠dica
        clarity=20.0,
        abnt=10.0
    )
    
    print(f"‚úÖ Pesos personalizados criados:")
    print(f"   {custom_weights.to_percentage_dict()}")
    print(f"   Categoria dominante: {custom_weights.get_dominant_category()}")
    print(f"   Tipo de distribui√ß√£o: {custom_weights.get_weight_distribution_type()}")
    
    # 2. Testar preset padr√£o
    standard_weights = AnalysisWeights.from_preset(AnalysisPreset.STANDARD)
    print(f"‚úÖ Preset padr√£o: {standard_weights.to_percentage_dict()}")
    
    # 3. Criar regra personalizada
    custom_rule = CustomRule(
        name="Verificar Valor Estimado",
        description="Verifica se o valor estimado est√° claramente especificado",
        pattern=r"valor\s+estimado\s*:\s*R\$\s*[\d.,]+",
        pattern_type="regex",
        severity="alta",
        category="estrutural",
        message="Valor estimado n√£o encontrado ou mal formatado",
        suggestion="Inclua o valor estimado no formato: 'Valor Estimado: R$ XX.XXX,XX'",
        applies_to_document_types=[DocumentType.EDITAL, DocumentType.TERMO_REFERENCIA]
    )
    
    print(f"‚úÖ Regra personalizada criada: {custom_rule.name}")
    print(f"   Categoria: {custom_rule.category}")
    print(f"   Severidade: {custom_rule.severity}")
    
    # 4. Testar padr√£o da regra
    test_text = "O valor estimado para esta contrata√ß√£o √© R$ 50.000,00"
    match_result = custom_rule.test_pattern_match(test_text)
    print(f"‚úÖ Teste de padr√£o: {'‚úì Match' if match_result else '‚úó No match'}")
    
    # 5. Criar configura√ß√£o organizacional completa
    org_config = OrganizationConfig(
        organization_id="org_prefeitura_sp",
        organization_name="Prefeitura Municipal de S√£o Paulo",
        weights=custom_weights,
        preset_type=AnalysisPreset.RIGOROUS,
        custom_rules=[custom_rule]
    )
    
    print(f"‚úÖ Configura√ß√£o organizacional criada:")
    print(f"   Organiza√ß√£o: {org_config.organization_name}")
    print(f"   Preset: {org_config.preset_type.value}")
    print(f"   Hash de config: {org_config.get_config_hash()[:8]}...")
    
    # 6. Testar m√©todos da configura√ß√£o
    org_config.add_custom_rule(CustomRule(
        name="Verificar Prazo de Entrega",
        description="Verifica se o prazo de entrega est√° especificado",
        pattern="prazo.*entrega",
        severity="media",
        category="estrutural",
        message="Prazo de entrega n√£o especificado",
        suggestion="Incluir prazo espec√≠fico de entrega"
    ))
    
    print(f"‚úÖ Regra adicional adicionada. Total: {len(org_config.custom_rules)}")
    
    # 7. Testar sum√°rio da configura√ß√£o
    summary = org_config.get_analysis_summary()
    print(f"‚úÖ Sum√°rio da configura√ß√£o:")
    for key, value in summary.items():
        print(f"   {key}: {value}")
    
    return org_config


def test_analysis_models():
    """Testa modelos de an√°lise."""
    print("\nüß™ Testando Analysis Models...")
    
    # 1. Criar scores de conformidade
    conformity_scores = ConformityScore(
        structural=85.0,
        legal=92.0,
        clarity=78.0,
        abnt=88.0,
        overall=86.0
    )
    
    print(f"‚úÖ Scores de conformidade criados:")
    print(f"   Estrutural: {conformity_scores.structural} ({conformity_scores.get_category_rating('structural')})")
    print(f"   Jur√≠dico: {conformity_scores.legal} ({conformity_scores.get_category_rating('legal')})")
    print(f"   Clareza: {conformity_scores.clarity} ({conformity_scores.get_category_rating('clarity')})")
    print(f"   ABNT: {conformity_scores.abnt} ({conformity_scores.get_category_rating('abnt')})")
    
    # 2. Criar findings
    findings = [
        AnalysisFinding(
            category=ProblemCategory.JURIDICO,
            severity=ProblemSeverity.ALTA,
            title="Aus√™ncia de Fundamenta√ß√£o Legal",
            description="O edital n√£o apresenta fundamenta√ß√£o legal adequada conforme Lei 14.133/2021",
            suggestion="Incluir refer√™ncias espec√≠ficas aos artigos da Lei 14.133/2021",
            location="Se√ß√£o 1.2 - Fundamenta√ß√£o Legal",
            regulatory_reference="Lei 14.133/2021, Art. 18",
            impact_score=7.5
        ),
        AnalysisFinding(
            category=ProblemCategory.ESTRUTURAL,
            severity=ProblemSeverity.MEDIA,
            title="Se√ß√£o de Cronograma Incompleta",
            description="O cronograma de execu√ß√£o n√£o detalha todas as etapas necess√°rias",
            suggestion="Detalhar cronograma com marcos espec√≠ficos e prazos intermedi√°rios",
            location="Se√ß√£o 4.1 - Cronograma",
            impact_score=5.0
        )
    ]
    
    print(f"‚úÖ {len(findings)} findings criados:")
    for finding in findings:
        print(f"   ‚Ä¢ {finding.title} ({finding.severity.value})")
        print(f"     Categoria: {finding.category.value}")
        print(f"     Impacto: {finding.impact_score}/10")
    
    # 3. Criar resultado de an√°lise
    org_config = OrganizationConfig.create_default_config(
        "org_test",
        "Organiza√ß√£o Teste",
        AnalysisPreset.RIGOROUS
    )
    
    # Calcular score ponderado
    weighted_score = conformity_scores.calculate_weighted_score(org_config.weights)
    
    analysis_result = AnalysisResult(
        document_id="doc_test_123",
        organization_id="org_test",
        conformity_scores=conformity_scores,
        weighted_score=weighted_score,
        findings=findings,
        recommendations=[
            "Revisar fundamenta√ß√£o legal do edital",
            "Detalhar cronograma de execu√ß√£o",
            "Incluir crit√©rios de sustentabilidade"
        ],
        applied_config=org_config,
        execution_time_seconds=12.5,
        analysis_metadata={
            "ocr_used": True,
            "ai_analysis": False,
            "custom_rules_applied": len(org_config.custom_rules)
        }
    )
    
    print(f"‚úÖ Resultado de an√°lise criado:")
    print(f"   Document ID: {analysis_result.document_id}")
    print(f"   Score Ponderado: {analysis_result.weighted_score:.1f}")
    print(f"   Total de Findings: {len(analysis_result.findings)}")
    print(f"   Tempo de Execu√ß√£o: {analysis_result.execution_time_seconds}s")
    
    # 4. Testar m√©todos de agrupamento
    findings_by_severity = analysis_result.get_findings_by_severity()
    print(f"‚úÖ Findings por severidade:")
    for severity, findings_list in findings_by_severity.items():
        print(f"   {severity.title()}: {len(findings_list)}")
    
    # 5. Gerar sum√°rio executivo
    executive_summary = analysis_result.generate_executive_summary()
    print(f"‚úÖ Sum√°rio executivo gerado:")
    print(f"   Score Geral: {executive_summary['overall_score']}")
    print(f"   Issues Cr√≠ticos: {executive_summary['critical_issues']}")
    print(f"   Issues Alta Prioridade: {executive_summary['high_priority_issues']}")
    
    return analysis_result


def test_utils_and_serialization():
    """Testa utilit√°rios e serializa√ß√£o."""
    print("\nüîß Testando Utils e Serializa√ß√£o...")
    
    # Criar dados de teste
    document = test_document_models()
    org_config = test_config_models()
    analysis_result = test_analysis_models()
    
    print("\nüìÑ Testando convers√µes:")
    
    # 1. Converter documento para sum√°rio
    doc_summary = create_document_summary(document)
    print(f"‚úÖ Sum√°rio do documento criado:")
    print(f"   ID: {doc_summary['id']}")
    print(f"   Tipo: {doc_summary['type']}")
    print(f"   Arquivo: {doc_summary['file_info']['name']}")
    
    # 2. Converter configura√ß√£o para frontend
    frontend_config = prepare_frontend_config(org_config)
    print(f"‚úÖ Config para frontend preparada:")
    print(f"   Organization ID: {frontend_config['organizationId']}")
    print(f"   Preset: {frontend_config['presetType']}")
    print(f"   Categoria Dominante: {frontend_config['dominantCategory']}")
    
    # 3. Converter an√°lise para dashboard
    dashboard_data = create_dashboard_data(analysis_result)
    print(f"‚úÖ Dados do dashboard criados:")
    print(f"   Score Geral: {dashboard_data['overall_score']}")
    print(f"   Total Issues: {dashboard_data['findings_summary']['total']}")
    print(f"   Preset Aplicado: {dashboard_data['applied_preset']}")
    
    # 4. Testar serializa√ß√£o JSON
    config_json = SerializationUtils.export_config_to_json(org_config, pretty=True)
    print(f"‚úÖ Configura√ß√£o exportada para JSON ({len(config_json)} chars)")
    
    # 5. Testar importa√ß√£o de JSON
    imported_config = SerializationUtils.import_config_from_json(config_json)
    print(f"‚úÖ Configura√ß√£o importada de JSON:")
    print(f"   Hash original: {org_config.get_config_hash()[:8]}...")
    print(f"   Hash importado: {imported_config.get_config_hash()[:8]}...")
    print(f"   Consistente: {'‚úì' if org_config.get_config_hash() == imported_config.get_config_hash() else '‚úó'}")
    
    # 6. Testar valida√ß√£o de consist√™ncia
    validation_result = ValidationUtils.validate_analysis_consistency(
        document, analysis_result, org_config
    )
    print(f"‚úÖ Valida√ß√£o de consist√™ncia:")
    print(f"   V√°lido: {'‚úì' if validation_result['is_valid'] else '‚úó'}")
    if validation_result['errors']:
        print(f"   Erros: {validation_result['errors']}")
    if validation_result['warnings']:
        print(f"   Warnings: {validation_result['warnings']}")


def demonstrate_core_differentiator():
    """üöÄ Demonstra o CORE DIFERENCIAL - Par√¢metros Personalizados."""
    print("\nüöÄ DEMONSTRA√á√ÉO DO CORE DIFERENCIAL")
    print("=" * 50)
    print("Sistema de Par√¢metros Personalizados por Organiza√ß√£o")
    print("=" * 50)
    
    # Simular 3 organiza√ß√µes com perfis diferentes
    organizations = [
        {
            'name': 'Tribunal de Contas',
            'preset': AnalysisPreset.RIGOROUS,
            'weights': AnalysisWeights(structural=15.0, legal=60.0, clarity=20.0, abnt=5.0),
            'focus': 'Conformidade Legal Rigorosa'
        },
        {
            'name': 'Prefeitura T√©cnica',
            'preset': AnalysisPreset.TECHNICAL,
            'weights': AnalysisWeights(structural=35.0, legal=25.0, clarity=15.0, abnt=25.0),
            'focus': 'Especifica√ß√µes T√©cnicas Detalhadas'
        },
        {
            'name': '√ìrg√£o Padr√£o',
            'preset': AnalysisPreset.STANDARD,
            'weights': AnalysisWeights(structural=25.0, legal=25.0, clarity=25.0, abnt=25.0),
            'focus': 'An√°lise Balanceada'
        }
    ]
    
    # Scores base do mesmo documento
    base_scores = ConformityScore(
        structural=80.0,
        legal=70.0,
        clarity=85.0,
        abnt=90.0,
        overall=81.25  # M√©dia simples
    )
    
    print(f"\nüìä IMPACTO DOS PESOS PERSONALIZADOS:")
    print(f"Score base (sem pesos): Estrutural={base_scores.structural}%, "
          f"Jur√≠dico={base_scores.legal}%, Clareza={base_scores.clarity}%, "
          f"ABNT={base_scores.abnt}%")
    print(f"Score m√©dio simples: {base_scores.overall}%")
    
    print(f"\nüéØ SCORES PERSONALIZADOS POR ORGANIZA√á√ÉO:")
    
    for i, org in enumerate(organizations, 1):
        weighted_score = base_scores.calculate_weighted_score(org['weights'])
        
        print(f"\n{i}. {org['name']} - {org['focus']}")
        print(f"   Pesos: {org['weights'].to_percentage_dict()}")
        print(f"   Score Personalizado: {weighted_score:.1f}%")
        print(f"   Diferen√ßa vs. M√©dia: {weighted_score - base_scores.overall:+.1f}%")
        print(f"   Categoria Dominante: {org['weights'].get_dominant_category().title()}")
    
    print(f"\nüí° INSIGHTS:")
    print(f"   ‚Ä¢ Tribunal de Contas: Score mais baixo devido ao foco em conformidade legal")
    print(f"   ‚Ä¢ Prefeitura T√©cnica: Score mais alto devido √†s boas especifica√ß√µes ABNT")
    print(f"   ‚Ä¢ √ìrg√£o Padr√£o: Score equilibrado reflete an√°lise geral")
    
    print(f"\nüöÄ DIFERENCIAL COMPETITIVO DEMONSTRADO:")
    print(f"   ‚úì Mesmo documento = Scores diferentes por organiza√ß√£o")
    print(f"   ‚úì An√°lise adaptada √†s necessidades espec√≠ficas")
    print(f"   ‚úì Flexibilidade total nos crit√©rios de avalia√ß√£o")
    print(f"   ‚úì Personaliza√ß√£o por tipo de √≥rg√£o e processo")


def main():
    """Fun√ß√£o principal para executar todos os testes."""
    print("üß™ LicitaReview - Teste Completo dos Modelos Python")
    print("=" * 60)
    
    try:
        # Testes individuais
        test_document_models()
        test_config_models()
        test_analysis_models()
        test_utils_and_serialization()
        
        # Demonstra√ß√£o do diferencial
        demonstrate_core_differentiator()
        
        print(f"\n‚úÖ TODOS OS TESTES CONCLU√çDOS COM SUCESSO!")
        print(f"üöÄ Sistema de Par√¢metros Personalizados funcionando perfeitamente!")
        
    except Exception as e:
        print(f"\n‚ùå ERRO nos testes: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()