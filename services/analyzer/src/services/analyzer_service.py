"""
LicitaReview - Servi√ßo Principal de An√°lise

Este m√≥dulo integra o motor de an√°lise adaptativo com o sistema de an√°lise
padr√£o, coordenando an√°lises personalizadas e gerenciando cache de resultados.
"""

from datetime import datetime
from typing import Dict, List, Optional, Any
import hashlib
import re
from dataclasses import dataclass

import structlog
from fastapi import UploadFile

from .adaptive_analyzer import AdaptiveAnalyzer
from ..models.document_models import Document
from ..models.config_models import OrganizationConfig, AnalysisWeights, AnalysisPreset
from ..models.analysis_models import (
    AnalysisRequest, 
    AnalysisResult, 
    DocumentUploadResponse
)

logger = structlog.get_logger(__name__)


@dataclass
class CachedResult:
    """Resultado em cache com metadados."""
    result: AnalysisResult
    cached_at: datetime
    cache_key: str
    ttl_minutes: int = 60


class AnalyzerService:
    """
    Servi√ßo principal de an√°lise que coordena o motor adaptativo.
    
    Responsabilidades:
    - Gerenciar an√°lises com par√¢metros personalizados
    - Cache inteligente de resultados
    - Processamento de uploads de documentos  
    - Coordena√ß√£o entre an√°lises padr√£o e adaptativas
    - Valida√ß√£o de configura√ß√µes organizacionais
    """
    
    def __init__(self):
        self.logger = structlog.get_logger(self.__class__.__name__)
        self.cache: Dict[str, CachedResult] = {}
        self.is_initialized = False
    
    async def initialize(self):
        """Inicializa o servi√ßo de an√°lise."""
        if self.is_initialized:
            return
        
        self.logger.info("üöÄ Initializing AnalyzerService")
        
        # Aqui voc√™ pode adicionar inicializa√ß√µes de recursos
        # como conex√µes de banco de dados, carregamento de modelos, etc.
        
        self.is_initialized = True
        self.logger.info("‚úÖ AnalyzerService initialized successfully")
    
    async def cleanup(self):
        """Limpa recursos do servi√ßo."""
        self.logger.info("üßπ Cleaning up AnalyzerService")
        self.cache.clear()
        self.is_initialized = False
    
    async def analyze_document(self, request: AnalysisRequest) -> AnalysisResult:
        """
        üö® M√âTODO PRINCIPAL - Executa an√°lise de documento com par√¢metros personalizados.
        
        Args:
            request: Request de an√°lise com configura√ß√£o organizacional
            
        Returns:
            AnalysisResult com an√°lise personalizada
        """
        start_time = datetime.utcnow()
        
        self.logger.info(
            "üìã Starting document analysis",
            document_id=request.document_id,
            organization_id=request.organization_config.organization_id,
            analysis_type=request.analysis_type
        )
        
        try:
            # 1. Verifica cache se n√£o for reanalise for√ßada
            if not request.force_reanalysis:
                cached_result = await self._get_cached_result(request)
                if cached_result:
                    self.logger.info(
                        "‚úÖ Returning cached result",
                        document_id=request.document_id,
                        cache_age_minutes=(datetime.utcnow() - cached_result.cached_at).seconds // 60
                    )
                    return cached_result.result
            
            # 2. Carrega documento (simulado - em produ√ß√£o viria do banco de dados)
            document = await self._load_document(request.document_id)
            if not document:
                raise ValueError(f"Document {request.document_id} not found")
            
            # 3. Determina tipo de documento
            doc_type = await self._determine_document_type(document)
            
            # 4. Cria analisador adaptativo
            adaptive_analyzer = AdaptiveAnalyzer(
                doc_type=doc_type,
                org_config=request.organization_config
            )
            
            # 5. Executa an√°lise adaptativa
            result = await adaptive_analyzer.analyze_with_custom_params(document)
            
            # 6. Adiciona metadados do request
            result.request_id = id(request)  # Simulado
            result.analysis_metadata.update({
                'request_analysis_type': request.analysis_type,
                'custom_parameters': request.custom_parameters,
                'minimum_confidence': request.minimum_confidence,
                'include_suggestions': request.include_suggestions,
                'requested_by': request.requested_by,
                'priority': request.priority
            })
            
            # 7. Filtra findings por confian√ßa m√≠nima
            if request.minimum_confidence > 0:
                result.findings = [
                    f for f in result.findings 
                    if f.confidence >= request.minimum_confidence
                ]
            
            # 8. Limita n√∫mero de findings se especificado
            if request.max_findings and len(result.findings) > request.max_findings:
                # Mant√©m findings mais cr√≠ticos
                result.findings = sorted(
                    result.findings,
                    key=lambda f: (f.get_severity_weight(), f.confidence),
                    reverse=True
                )[:request.max_findings]
            
            # 9. Cache do resultado
            await self._cache_result(request, result)
            
            execution_time = (datetime.utcnow() - start_time).total_seconds()
            
            self.logger.info(
                "‚úÖ Document analysis completed",
                document_id=request.document_id,
                organization_id=request.organization_config.organization_id,
                weighted_score=result.weighted_score,
                findings_count=len(result.findings),
                execution_time=execution_time
            )
            
            return result
            
        except Exception as e:
            self.logger.error(
                "‚ùå Document analysis failed",
                document_id=request.document_id,
                organization_id=request.organization_config.organization_id,
                error=str(e),
                error_type=type(e).__name__
            )
            raise
    
    async def process_upload(self, file: UploadFile) -> DocumentUploadResponse:
        """
        Processa upload de documento e prepara para an√°lise.
        
        Args:
            file: Arquivo enviado
            
        Returns:
            DocumentUploadResponse com informa√ß√µes do documento processado
        """
        self.logger.info("üì§ Processing document upload", filename=file.filename)
        
        try:
            # 1. L√™ conte√∫do do arquivo
            content = await file.read()
            
            # 2. Extrai texto baseado no tipo de arquivo
            if file.content_type == "application/pdf":
                extracted_text = await self._extract_text_from_pdf(content)
            elif file.content_type in [
                "application/msword",
                "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            ]:
                extracted_text = await self._extract_text_from_word(content)
            else:
                extracted_text = content.decode('utf-8', errors='ignore')
            
            # 3. Cria documento
            document_id = hashlib.md5(content).hexdigest()
            
            document = Document(
                id=document_id,
                title=file.filename or "Documento Sem T√≠tulo",
                content=extracted_text,
                file_type=file.content_type,
                file_size=len(content),
                uploaded_at=datetime.utcnow()
            )
            
            # 4. Salva documento (simulado - em produ√ß√£o salvaria no banco)
            await self._save_document(document)
            
            # 5. Determina tipo do documento
            doc_type = await self._determine_document_type(document)
            
            response = DocumentUploadResponse(
                document_id=document_id,
                filename=file.filename,
                file_type=file.content_type,
                file_size=len(content),
                extracted_text_length=len(extracted_text),
                document_type=doc_type,
                processing_status="completed",
                upload_timestamp=datetime.utcnow()
            )
            
            self.logger.info(
                "‚úÖ Document upload processed",
                document_id=document_id,
                filename=file.filename,
                text_length=len(extracted_text)
            )
            
            return response
            
        except Exception as e:
            self.logger.error(
                "‚ùå Document upload processing failed",
                filename=file.filename,
                error=str(e)
            )
            raise
    
    async def get_analysis_presets(self) -> Dict[str, Any]:
        """
        Retorna presets de an√°lise dispon√≠veis.
        
        Returns:
            Dict com presets e suas configura√ß√µes
        """
        presets = {}
        
        for preset in AnalysisPreset:
            if preset == AnalysisPreset.CUSTOM:
                continue
            
            weights = AnalysisWeights.from_preset(preset)
            presets[preset.value] = {
                'name': preset.value.title(),
                'description': self._get_preset_description(preset),
                'weights': weights.dict(),
                'weight_distribution': weights.get_weight_distribution_type(),
                'dominant_category': weights.get_dominant_category(),
                'suitable_for': self._get_preset_suitable_for(preset)
            }
        
        return {
            'available_presets': presets,
            'custom_preset_info': {
                'name': 'Custom',
                'description': 'Configura√ß√£o totalmente personalizada pela organiza√ß√£o',
                'allows_custom_weights': True,
                'allows_custom_rules': True,
                'allows_templates': True
            }
        }
    
    async def validate_config(self, config: OrganizationConfig) -> Dict[str, Any]:
        """
        Valida configura√ß√£o organizacional.
        
        Args:
            config: Configura√ß√£o a ser validada
            
        Returns:
            Resultado da valida√ß√£o
        """
        self.logger.info(
            "üîç Validating organization config",
            organization_id=config.organization_id
        )
        
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'suggestions': [],
            'config_summary': config.get_analysis_summary()
        }
        
        try:
            # Valida√ß√£o de pesos
            weights_sum = (
                config.weights.structural + 
                config.weights.legal + 
                config.weights.clarity + 
                config.weights.abnt
            )
            
            if abs(weights_sum - 100.0) > 0.01:
                validation_result['errors'].append(
                    f"Soma dos pesos deve ser 100%, atual: {weights_sum:.2f}%"
                )
                validation_result['is_valid'] = False
            
            # Valida√ß√£o de regras personalizadas
            for rule in config.custom_rules:
                try:
                    # Testa padr√£o regex
                    rule.test_pattern_match("teste")
                except Exception as e:
                    validation_result['errors'].append(
                        f"Regra '{rule.name}' tem padr√£o inv√°lido: {str(e)}"
                    )
                    validation_result['is_valid'] = False
            
            # Sugest√µes baseadas na configura√ß√£o
            if config.weights.get_weight_distribution_type() == "legal_focused":
                validation_result['suggestions'].append(
                    "Configura√ß√£o focada em aspectos jur√≠dicos. "
                    "Considere balancear com aspectos estruturais para an√°lise mais completa."
                )
            
            if len(config.get_active_rules()) == 0:
                validation_result['warnings'].append(
                    "Nenhuma regra personalizada ativa. "
                    "Considere adicionar regras espec√≠ficas para sua organiza√ß√£o."
                )
            
            if len(config.templates) == 0:
                validation_result['warnings'].append(
                    "Nenhum template organizacional definido. "
                    "Templates ajudam a garantir estrutura padronizada dos documentos."
                )
            
        except Exception as e:
            validation_result['errors'].append(f"Erro na valida√ß√£o: {str(e)}")
            validation_result['is_valid'] = False
        
        self.logger.info(
            "‚úÖ Config validation completed",
            organization_id=config.organization_id,
            is_valid=validation_result['is_valid'],
            errors_count=len(validation_result['errors']),
            warnings_count=len(validation_result['warnings'])
        )
        
        return validation_result
    
    async def _get_cached_result(self, request: AnalysisRequest) -> Optional[CachedResult]:
        """Busca resultado em cache."""
        cache_key = request.get_cache_key()
        
        if cache_key not in self.cache:
            return None
        
        cached = self.cache[cache_key]
        
        # Verifica TTL
        age_minutes = (datetime.utcnow() - cached.cached_at).seconds // 60
        if age_minutes > cached.ttl_minutes:
            del self.cache[cache_key]
            return None
        
        return cached
    
    async def _cache_result(self, request: AnalysisRequest, result: AnalysisResult):
        """Armazena resultado em cache."""
        cache_key = request.get_cache_key()
        
        cached = CachedResult(
            result=result,
            cached_at=datetime.utcnow(),
            cache_key=cache_key,
            ttl_minutes=60  # Cache por 1 hora
        )
        
        self.cache[cache_key] = cached
        
        # Limita tamanho do cache
        if len(self.cache) > 1000:
            # Remove entradas mais antigas
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k].cached_at)
            del self.cache[oldest_key]
    
    async def _load_document(self, document_id: str) -> Optional[Document]:
        """
        Carrega documento pelo ID.
        
        Em produ√ß√£o, este m√©todo faria consulta ao banco de dados.
        """
        # Simula√ß√£o - em produ√ß√£o viria do banco de dados
        return Document(
            id=document_id,
            title="Documento de Teste",
            content="""
            EDITAL DE PREG√ÉO ELETR√îNICO N¬∫ 001/2024
            
            OBJETO: Aquisi√ß√£o de equipamentos de inform√°tica para moderniza√ß√£o
            do parque tecnol√≥gico da administra√ß√£o municipal.
            
            PRAZO: 30 (trinta) dias corridos para entrega.
            
            VALOR ESTIMADO: R$ 150.000,00 (cento e cinquenta mil reais).
            
            DA HABILITA√á√ÉO:
            Para participar do certame, os licitantes dever√£o apresentar:
            a) Certid√£o de regularidade fiscal;
            b) Comprova√ß√£o de aptid√£o t√©cnica;
            c) Qualifica√ß√£o econ√¥mico-financeira.
            
            Este edital segue as disposi√ß√µes da Lei 8.666/93 e Lei 14.133/21.
            """,
            file_type="text/plain",
            uploaded_at=datetime.utcnow()
        )
    
    async def _save_document(self, document: Document):
        """Salva documento (simulado)."""
        # Em produ√ß√£o, salvaria no banco de dados
        pass
    
    async def _determine_document_type(self, document: Document) -> str:
        """
        Determina tipo do documento baseado no conte√∫do.
        
        Args:
            document: Documento a ser analisado
            
        Returns:
            Tipo do documento identificado
        """
        content = (document.content or "").lower()
        
        # Padr√µes para identifica√ß√£o de tipos
        patterns = {
            'pregao': [r'preg√£o', r'pregao'],
            'edital': [r'edital'],
            'contrato': [r'contrato', r'instrumento'],
            'termo_referencia': [r'termo\s+de\s+refer√™ncia', r'termo\s+referencia'],
            'ata': [r'ata\s+de\s+registro'],
        }
        
        for doc_type, type_patterns in patterns.items():
            if any(re.search(pattern, content) for pattern in type_patterns):
                return doc_type
        
        return 'documento'  # Tipo gen√©rico
    
    async def _extract_text_from_pdf(self, content: bytes) -> str:
        """Extrai texto de PDF (simulado)."""
        # Em produ√ß√£o, usaria bibliotecas como PyPDF2, pdfplumber, etc.
        return "Texto extra√≠do de PDF (simulado)"
    
    async def _extract_text_from_word(self, content: bytes) -> str:
        """Extrai texto de Word (simulado)."""
        # Em produ√ß√£o, usaria bibliotecas como python-docx, etc.
        return "Texto extra√≠do de Word (simulado)"
    
    def _get_preset_description(self, preset: AnalysisPreset) -> str:
        """Retorna descri√ß√£o do preset."""
        descriptions = {
            AnalysisPreset.RIGOROUS: "M√°xima conformidade jur√≠dica e controle rigoroso",
            AnalysisPreset.STANDARD: "Configura√ß√£o equilibrada para uso geral",
            AnalysisPreset.FLEXIBLE: "An√°lise mais flex√≠vel para processos expeditos",
            AnalysisPreset.TECHNICAL: "Foco em aspectos t√©cnicos e normas ABNT"
        }
        return descriptions.get(preset, "Configura√ß√£o personalizada")
    
    def _get_preset_suitable_for(self, preset: AnalysisPreset) -> List[str]:
        """Retorna lista de casos adequados para o preset."""
        suitable_for = {
            AnalysisPreset.RIGOROUS: [
                "√ìrg√£os de controle (TCU, CGU)",
                "Contratos de alto valor",
                "Obras p√∫blicas complexas"
            ],
            AnalysisPreset.STANDARD: [
                "Prefeituras municipais",
                "√ìrg√£os estaduais",
                "Preg√µes eletr√¥nicos gerais"
            ],
            AnalysisPreset.FLEXIBLE: [
                "Compras de baixo valor",
                "Processos urgentes",
                "An√°lises preliminares"
            ],
            AnalysisPreset.TECHNICAL: [
                "Projetos de engenharia",
                "Especifica√ß√µes t√©cnicas",
                "Documentos com normas ABNT"
            ]
        }
        return suitable_for.get(preset, [])